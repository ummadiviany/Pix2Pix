{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY90WzMkg4XPCWObyd1Rls",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ummadiviany/Pix2Pix/blob/main/Training_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNzIHx9YGBtU"
      },
      "source": [
        "# Pix2Pix Training Notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6797pkZeGKMh"
      },
      "source": [
        "## Installing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-kzCLzY0Fe4",
        "outputId": "acbd8821-a9d8-4ff8-9f67-2ebe89cb0a54"
      },
      "source": [
        "!pip install -q albumentations==0.4.6   # Albumentations for data augumentation \n",
        "!pip install -q opendatasets    # To download datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 117 kB 10.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 948 kB 46.1 MB/s \n",
            "\u001b[?25h  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc1XKcgkGPu7"
      },
      "source": [
        "## Importing necessary libraries\n",
        "- You should be able to see **Successfully imported all libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5TYKeQi02Sz",
        "outputId": "086a0acd-a398-41e6-bbed-d8f2d40b4db8"
      },
      "source": [
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.optim as optim\n",
        "    from torch.utils.data import DataLoader, Dataset\n",
        "    import tqdm as tqdm\n",
        "    from torchvision.utils import save_image, make_grid\n",
        "    import albumentations as A\n",
        "    from albumentations.pytorch import ToTensorV2\n",
        "    import os\n",
        "    import numpy as np\n",
        "    from PIL import Image # Image reading \n",
        "    from torchvision import datasets\n",
        "    import matplotlib.pyplot as plt # Image display\n",
        "    import opendatasets as od # dataset download\n",
        "    %matplotlib inline  \n",
        "    import pandas as pd # for creating Loss dataframe\n",
        "    \n",
        "    print(\"Successfully imported all libraries\")\n",
        "except:\n",
        "    print(\"Errors in importing libraries\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully imported all libraries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UqcVaYMGU__"
      },
      "source": [
        "## Cloning git repo for model functions\n",
        "- I have all the model and additional function classes stored in my github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT6Ktx-B02Yz",
        "outputId": "9695152e-f3a3-4d3f-dfca-aaae58f51354"
      },
      "source": [
        "!git clone https://github.com/ummadiviany/Pix2Pix"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Pix2Pix' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yl00zAc02b5"
      },
      "source": [
        "from Pix2Pix.training_notebooks.generator_model import Generator\n",
        "from Pix2Pix.training_notebooks.discriminator_model import Discriminator\n",
        "from Pix2Pix.training_notebooks.dataset import MapDataset\n",
        "from Pix2Pix.training_notebooks.additional_functions import test_on_val_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HjnYEDbGd3D"
      },
      "source": [
        "## Datasets download - Attention Needed\n",
        "Use the below kaggle usename and key for dataset download\n",
        "1. Below code cell prompts for kaggle username, copy the username from below and paste and hit ‚å®Enter key.\n",
        "2. Again prompts for kaggle secure key, copy the key from below and paste and hit ‚å®Enter key.\n",
        "3. It will take about ~2min‚è≤ to download the datasets\n",
        "- username ‚ñ∂     **iamvinayummadi** \n",
        "- key:     ‚ñ∂    **78f6cee94760fd02415c9024cba10173**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7RAH-Cw4G-K",
        "outputId": "fc00e86c-10df-49c8-ac29-9976ccef86e8"
      },
      "source": [
        "od.download('https://www.kaggle.com/vikramtiwari/pix2pix-dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: iamvinayummadi\n",
            "Your Kaggle Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Downloading pix2pix-dataset.zip to ./pix2pix-dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 1.61G/2.40G [00:41<00:16, 52.0MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbfx34KpHBl5"
      },
      "source": [
        "## Setting up hyperparameters\n",
        "\n",
        "1.   Change the **NUM_EPOCHS=2** if needed\n",
        "2.   Change **BATCH_SIZE = 32** if needed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dai5Hfb02e9"
      },
      "source": [
        "NUM_EPOCHS = 2\n",
        "loss_df = pd.DataFrame(columns=['D_Loss','G_Loss'])\n",
        "LEARNING_RATE  = 3e-4\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS_IMG = 3\n",
        "L1_LAMBDA = 100\n",
        "LAMBDA_GP = 10\n",
        "TRAIN_DIR = \"pix2pix-dataset/maps/maps/train\"\n",
        "VAL_DIR = \"pix2pix-dataset/maps/maps/val\"\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device :',DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DVZ8ML1HSB-"
      },
      "source": [
        "## Loading training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v72-2h0h9F2S"
      },
      "source": [
        "train_dataset = MapDataset(root_dir= TRAIN_DIR, input_size=600,direction=0)\n",
        "train_loader = DataLoader(train_dataset,batch_size= BATCH_SIZE,shuffle=True,num_workers= NUM_WORKERS)\n",
        "\n",
        "val_dataset  = MapDataset(root_dir= VAL_DIR, input_size=600,direction=0)\n",
        "validation_loader = DataLoader(val_dataset,batch_size=4,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWZSomY7Hc93"
      },
      "source": [
        "## Model instances, optimizers, learning_rate schedulers, and loss functions\n",
        "1. Adam optimizer(lr = 2e-4,betas=(0.5,0.99) with stepwise learning rate decay is used. Learning rate decay by factor of 10 for every 20 epochs.\n",
        "2. BCE Loss for Discriminator and BCE + L1 Loss for Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv4DCnlc9BQk"
      },
      "source": [
        "disc = Discriminator(in_channels=3).to( DEVICE)\n",
        "gen_model = Generator(in_channels=3,features=64).to( DEVICE)\n",
        "\n",
        "opt_disc = optim.Adam(disc.parameters(),lr= LEARNING_RATE,betas=(0.5,0.999))\n",
        "opt_gen = optim.Adam(gen_model.parameters(),lr= LEARNING_RATE,betas=(0.5,0.999))\n",
        "\n",
        "scheduler_disc = optim.lr_scheduler.StepLR(opt_disc, step_size=20, gamma=0.1)\n",
        "scheduler_gen = optim.lr_scheduler.StepLR(opt_gen, step_size=20, gamma=0.1)\n",
        "\n",
        "BCE = nn.BCEWithLogitsLoss()\n",
        "L1_LOSS = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7kPqjTIHsWh"
      },
      "source": [
        "## Training loop\n",
        "* Prints Epoch, Batch, Discriminator Loss, Generator Loss\n",
        "* Saves an Imageüì∫ with name format input_label_gen_.png for visualization. Please check that imageüì∫"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ejoP1b02k7"
      },
      "source": [
        "for epoch in range( NUM_EPOCHS):\n",
        "    print(f\"Epoch[{epoch}/{NUM_EPOCHS}], Learning Rate = {opt_disc.param_groups[0]['lr']}\") # printing learning rate\n",
        "    for idx,(inputs,outputs) in enumerate(train_loader):    #enumerating thorugh train-dataset\n",
        "        inputs,outputs=inputs.to( DEVICE), outputs.to( DEVICE)  # sending to GPU\n",
        "        \n",
        "        #Train Discriminator\n",
        "        outputs_fake = gen_model(inputs)    #Generating translated images\n",
        "        D_real = disc(inputs,outputs)       # Discriminator call on inputs and outputs ones\n",
        "        D_real_loss = BCE(D_real,torch.ones_like(D_real))   # Calculates loss value\n",
        "        D_fake = disc(inputs,outputs_fake.detach())         # Discriminator call on inputs and genrated ones\n",
        "        D_fake_loss = BCE(D_fake,torch.zeros_like(D_fake))  # Calculates loss value\n",
        "        D_loss = (D_real_loss+D_fake_loss)/2                # Aggeregate loss\n",
        "        opt_disc.zero_grad()                # clearing optimizer gradients\n",
        "        D_loss.backward()                   # Backward function call\n",
        "        opt_disc.step()                     # Taking one optimizer step\n",
        "        \n",
        "        # Train Generator\n",
        "        D_fake = disc(inputs,outputs_fake)  # Discriminator call on inputs and genrated ones\n",
        "        G_fake_loss = BCE(D_fake,torch.ones_like(D_fake))   # Calculates loss value\n",
        "        L1 = L1_LOSS(outputs_fake,outputs)* L1_LAMBDA       # Calculates loss value\n",
        "        G_loss = G_fake_loss+L1             # Generator loss\n",
        "        opt_gen.zero_grad()                 # clearing optimizer gradients\n",
        "        G_loss.backward()                   # Backward function call\n",
        "        opt_gen.step()                      # Taking one optimizer step\n",
        "        \n",
        "        loss_df.loc[len(loss_df)] = [D_loss.mean().item(),G_loss.mean().item()]        # save loss value in dataframe row\n",
        "        loss_df.to_csv('losses.csv',index=False)                                       # write datafram file to disk\n",
        "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]  Batch [{idx+1}/{len(train_loader)}] PatchGAN_Loss : {D_loss.mean().item():.4f}  Generator_Loss : {G_loss.mean().item():.4f}\")\n",
        "        test_on_val_data(epoch, \"/content/\", gen_model, validation_loader, DEVICE)\n",
        "        \n",
        "    print('See the generated image at/content/input_label_gen_.png')\n",
        "    # Learning rate update with LR Scheduler\n",
        "    scheduler_disc.step()       # take one scheduler step\n",
        "    scheduler_gen.step()        # take one scheduler step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "107tKzMEQkVr"
      },
      "source": [
        "## Visualising results\n",
        "- Let'süëÄsee how are results at second epoch. Network needs to train for more than 250 epoch to get better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H5txRvNOKE6"
      },
      "source": [
        "def visualize(image):\n",
        "    img = Image.open(image)\n",
        "    plt.figure(figsize=(15,20))\n",
        "    plt.title('1st Row = Input Image,   2nd Row = Target Image,     3rd Row = Translated Image')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "visualize('input_label_gen_2.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxddB7hUGAKk"
      },
      "source": [
        "## Plotting Loss values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGB9eztQ020d"
      },
      "source": [
        "df_loss = pd.read_csv('losses.csv')\n",
        "plt.plot(df_loss['D_Loss'],label='PatchGAN Loss')\n",
        "plt.plot(df_loss['G_Loss'],label='Generator Loss')\n",
        "plt.xlabel('No of Batch Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB5ENXuuMVZc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}